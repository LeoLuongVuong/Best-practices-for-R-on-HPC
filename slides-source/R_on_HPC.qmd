---
title: "R on HPC"
author: "Mariana Montes, Ehsan Moravveji, Geert Jan Bex"
institution: "Vlaams Supercomputer Centrum"
date: today
format:
  revealjs:
    transiton: slide
    slide-number: true
    incremental: true
code-annotations: select
---

## Overview

- How to run R on HPC systems
  - Open OnDemand
  - Batch jobs
- Benchmarking: efficiency
- Improving performance
  - Profiling
  - Code optimization
  - Parallel computing

{{< include /_running_R_on_HPC_systems.qmd >}}


# Benchmarking: efficiency


## Efficiency?

Some R functions/operations are parallel under the hood

::: {.fragment}
```r
A <- matrix(rnorm(25), nrow=5)
B <- matrix(rnorm(25), nrow=5)
C <- A %*% B
```
:::

::: {.fragment}
How do you know?

- Check the documentation
_ Measure it
:::


## Parallel or not?

Time the execution of R script

```bash
$ time Rscript dgemm.R &> /dev/null

real    0m4.791s              # <1>
user    1m21.693s             # <2>
sys     0m31.345s
```

1. Real time, i.e., walltime
2. User time, i.e., CPU time used

82 seconds CPU time in 4.8 seconds walltime... [parallelism!]{.fragment}

::: {.fragment}
`%*%` use Basic Linear Algebra Subroutines (BLAS)

Uses multiple threads, each on a core
:::


## How to exploit that?

Easy: set `--cpus-per-task` > 1

::: {style="font-size: 80%;"}
| CPUs per task | walltime |
|---------------|----------|
| 1             | 109.6    |
| 2             |  64.8    |
| 4             |  50.5    |
| 8             |  40.2    |
| 12            |  34.3    |
| 16            |  33.2    |
| 32            |  31.8    |
:::

[Nice!]{.fragment}


## Speedup

$S(n) = \frac{T_1}{T_n}$

::: {style="font-size: 80%;"}
| $n$           | $T_n$    | $S(n)$  |
|---------------|----------|---------|
| 1             | 109.6    | 1.00    |
| 2             |  64.8    | 1.69    |
| 4             |  50.5    | 2.17    |
| 8             |  40.2    | 2.73    |
| 12            |  34.3    | 3.20    |
| 16            |  33.2    | 3.30    |
| 32            |  31.8    | 3.45    |
:::

[Nice? Maybe...]{.fragment}


## Parallel efficiency

$E(n) = \frac{T_1}{n \cdot T_n}$

::: {style="font-size: 80%;"}
| $n$           | $T_n$    | $S(n)$  | $E(n)$ |
|---------------|----------|---------|--------|
| 1             | 109.6    | 1.00    | 1.00   |
| 2             |  64.8    | 1.69    | 0.85   |
| 4             |  50.5    | 2.17    | 0.54   |
| 8             |  40.2    | 2.73    | 0.34   |
| 12            |  34.3    | 3.20    | 0.27   |
| 16            |  33.2    | 3.30    | 0.21   |
| 32            |  31.8    | 3.45    | 0.11   |
:::

[Nice?, not so much...]{.fragment} [HPC infrastructure is *very* expensive!]{.fragment}


## Lots of matrices to multiply

Same script, many parameter settings ($N$)

::::: {.columns}

:::: {.column width=50%}
::: {style="font-size: 75%;"}
| $N$           | $T_N$    | $S(N)$  | $E(N)$ |
|---------------|----------|---------|--------|
| 1             | 42.6     | 1.00    | 1.00   |
| 4             | 43.7     | 3.90    | 0.98   |
| 8             | 49.6     | 6.87    | 0.86   |
| 12            | 65.3     | 7.82    | 0.65   |
| 16            | 55.8     | 12.2    | 0.76   |
| 20            | 65.7     | 13.0    | 0.65   |
| 24            | 74.5     | 13.7    | 0.57   |
| 28            | 89.8     | 13.3    | 0.47   |
| 32            | 83.6     | 16.3    | 0.51   |
| 36            | 85.2     | 18.0    | 0.50   |
:::
::::

:::: {.column width=50% .fragment}
$N = 8$ seems optimal, but what the heck, you're ruining the node anyway

Better go all the way to $N = 36$
::::

:::::
