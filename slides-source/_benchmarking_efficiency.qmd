# Benchmarking: efficiency


## Efficiency?

Some R functions/operations are parallel under the hood

::: {.fragment}
```r
A <- matrix(rnorm(25), nrow=5)
result <- A
for (i in 1:(power-1)) {
    result <- result %*% A
}
```
:::

::: {.fragment}
How do you know?

- Check the documentation
- Measure it
:::


## Benchmark environment

Experiments done on Sapphire Rapids node

- 2 Intel Xeon Platinum 8468 48-core
- 256 GB RAM

Module R/4.4.0-gfbf-2023a


## Parallel or not?

Time the execution of R script

```bash
$ time Rscript dgemm.R &> /dev/null

real    0m4.791s              # <1>
user    1m21.693s             # <2>
sys     0m31.345s
```

1. Real time, i.e., walltime
2. User time, i.e., CPU time used

82 seconds CPU time in 4.8 seconds walltime... [parallelism!]{.fragment}

::: {.fragment}
`%*%` use Basic Linear Algebra Subroutines (BLAS)

Uses multiple threads, each on a core
:::


## How to exploit that?

Easy: set `--cpus-per-task` > 1

::: {style="font-size: 80%;"}
| CPUs per task ($n$) | walltime ($T_n$) |
|---------------------|------------------|
| 1                   | 109.6            |
| 2                   |  64.8            |
| 4                   |  50.5            |
| 8                   |  40.2            |
| 12                  |  34.3            |
| 24                  |  31.5            |
| 48                  |  31.0            |
| 96                  |  33.0            |
:::

[Nice!]{.fragment}

::: notes
Results from dgemm/slurm-multicore_benchmark.out
:::

## Speedup

$S(n) = \frac{T_1}{T_n}$

::: {style="font-size: 80%;"}
| $n$           | $T_n$    | $S(n)$  |
|---------------|----------|---------|
| 1             | 109.6    | 1.00    |
| 2             |  64.8    | 1.69    |
| 4             |  50.5    | 2.17    |
| 8             |  40.2    | 2.73    |
| 12            |  34.3    | 3.20    |
| 24            |  31.5    | 3.48    |
| 48            |  31.0    | 3.54    |
| 96            |  33.0    | 3.32    |
:::

[Nice? Maybe...]{.fragment}

::: notes
Results from dgemm/slurm-multicore_benchmark.out
:::


## Parallel efficiency

$E(n) = \frac{T_1}{n \cdot T_n}$

::: {style="font-size: 80%;"}
| $n$           | $T_n$    | $S(n)$  | $E(n)$ |
|---------------|----------|---------|--------|
| 1             | 109.6    | 1.00    | 1.00   |
| 2             |  64.8    | 1.69    | 0.85   |
| 4             |  50.5    | 2.17    | 0.54   |
| 8             |  40.2    | 2.73    | 0.34   |
| 12            |  34.3    | 3.20    | 0.27   |
| 24            |  31.5    | 3.48    | 0.14   |
| 48            |  31.0    | 3.54    | 0.07   |
| 96            |  33.0    | 3.32    | 0.03   |
:::

[Nice?, not so much...]{.fragment} [HPC infrastructure is *very* expensive!]{.fragment}

::: notes
Results from dgemm/slurm-multicore_benchmark.out
:::


## Lots of matrices to multiply

Same script, many parameter settings ($N$)

::::: {.columns}
:::: {.column width=50%}
::: {style="font-size: 75%;"}
| $N$           | $T_N$    | $S(N)$  | $E(N)$ |
|---------------|----------|---------|--------|
| 1             | 42.6     | 1.00    | 1.00   
| 4             | 43.7     | 3.90    | 0.98   |
| 8             | 49.6     | 6.87    | 0.86   |
| 12            | 65.3     | 7.82    | 0.65   |
| 24            | 74.5     | 13.7    | 0.|
| 36            | 85.2     | 18.0    | 0.50   |
| 48            | 94.3     | 21.6    | 0.45   |
:::
::::

:::: {.column width=50% .fragment}
$N = 8$ seems optimal, but what the heck, you're ruining the node anyway

Better go all the way to $N = 48$

::: {.callout-note}
`OMP_NUM_THREADS=2`
:::
::::
:::::

::: notes
Results from dgemm/slurm-multicore_gnu_parallel.out
:::


## Why performance degradation?

It's the memory architecture, stupid!

::: {style="font-size: 80%;"}
- 48 core Intel Sapphire Rapids CPU
  - L3 cache per socket: 105 MB
  - L2 cache per CPU (core): 2 MB
  - L1 cache per CPU (core): 48 kB data
  - 8 memory channels at 4800 MHz
- 36 core Intel Icelake
  - L3 cache per socket: 54 MB
  - L2 cache per CPU (core): 1.25 MB
  - L1 cache per CPU (core): 48 kB data
  - 8 memory channels at 3200 MHz
:::


## How to time?

- In job script: `time`
- In job script: `hyperfine`
  - Runs command multiple times
  - Reports mean, median, min, max, etc.
  - Can compare multiple commands
- For completed job
  ```bash
  $ sacct --cluster=<cluster> --format=JobID,TotalCPU,Elapsed --jobs=<job-id>
  ```
